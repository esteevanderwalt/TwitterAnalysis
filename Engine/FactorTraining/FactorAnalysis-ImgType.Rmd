---
title: "Attribute analysis - Type of Image"
output: 
  html_document: 
    keep_md: yes
---

```{r echo=FALSE, messages=FALSE, results='hide'}
#garbage collection + clear RAM
rm(list = ls(all.name = TRUE))
gc()
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(tidy = TRUE)
knitr::opts_chunk$set(warning = FALSE)
```

```{r include=FALSE}
  #load libraries
  library(knitr)
  library(ggplot2)
  library(scales)

```

## Connect to the database first
```{r echo=FALSE}
read_chunk('../../DBConnection/ConnectPostgres.R')
```

```{r connectDB, echo=FALSE}
```

##Get the tweets
```{r gettwitterfeeddata, cache=FALSE, echo=FALSE}
users <- dbGetQuery(con, "SELECT profile_image_type, background_image_type from main.experiment_user")
```

##Profile image type
```{r profile}
ggplot(data = users, aes(x = profile_image_type)) +
  geom_bar() +
  theme(legend.position = "none") +
  xlab("Profile") + ylab("Count") + 
  scale_fill_gradient(low = "midnightblue", high = "aquamarine4")
```

##Background image type
```{r background}
ggplot(data = users, aes(x = background_image_type)) +
  geom_bar() +
  theme(legend.position = "none") +
  xlab("Background") + ylab("Count") + 
  scale_fill_gradient(low = "midnightblue", high = "aquamarine4")
```

##Score the data

###first create a score
```{r score}
factor_no <- 3
exp_no <- 1
period_no <- 1

sql <- paste("DELETE FROM main.experiment_user_score where factor_no = 3",sep="")
dbSendQuery(con, sql)

sql <- paste("INSERT INTO main.experiment_user_score(experiment_no, period_no, userid, factor_no, idi_full)",sep="")
sql <- paste(sql, "select experiment_no, period_no, userid, 3,", sep="")
sql <- paste(sql, "case when profile_image_type = 'unique' then 1 else 0 end", sep="")    
sql <- paste(sql, " from main.experiment_user", sep="")
dbSendQuery(con, sql)
    
```

###show results
No scaling required

```{r score_n}
user.score <- dbGetQuery(con, "SELECT s.userid, s.idi_full, tz.continent from main.experiment_user_score s join main.experiment_user u on u.userid = s.userid left join main.timezone_r tz on tz.timezone = u.timezone where s.factor_no = 3 and s.experiment_no = u.experiment_no and s.period_no = u.period_no")

#user.scaled_score <- data.frame(as.data.frame( scale(user.score[1] )), user.score[2])
colnames(user.score) = c("userid", "idi","continent")

ggplot(user.score, aes(x=continent, y=idi)) +
  geom_boxplot(outlier.colour="red", outlier.shape=8, outlier.size=4) +
  stat_summary(fun.y=mean, geom="point", shape=23, size=4) 

```
##Outlier detection
Use Tukey's method to update all scores that were outliers

```{r outlier, results='hide'}

markoutlier <- function(x, exp_no, period_no, factor_no){
  sql <- paste("update main.experiment_user_score set outlier_full=1",sep="")
  sql <- paste(sql," where userid='",x["userid"] ,"'",sep="")
  sql <- paste(sql, " and experiment_no=",exp_no,sep="")
  sql <- paste(sql, " and period_no=",period_no,sep="")
  sql <- paste(sql, " and factor_no=",factor_no,sep="")
  dbSendQuery(con, sql, echo=FALSE)  
}

#TODO outliers per continent
continents <- unique(user.score$continent)

  user.continent_score <- user.score
  outlier <- boxplot.stats(user.continent_score$idi, coef = 1.5)$out
  user.outlier <- user.continent_score[user.continent_score$idi %in% outlier,]
  apply(user.outlier, 1, markoutlier, exp_no=exp_no, period_no=period_no,factor_no=factor_no)
  #na1 <- nrow(user.outlier)
  #Outliers identified:
  #na1
  #Propotion (%) of outliers:
  #round(na1 / sum(!is.na(user.continent_score$idi))*100, 1)

```

Total outliers: `r nrow(user.outlier)` out of `r nrow(user.score)`

```{r closeDB}
```